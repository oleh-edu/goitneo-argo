# MLOps Experiments â€“ Iris SGD Classification Demo

This repository demonstrates a **production-like MLOps workflow** for the Iris classification problem.  
It covers **model training & promotion with MLflow**, **containerized inference service with FastAPI**, **CI/CD with ArgoCD**, and **observability with Prometheus/Grafana**.

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ argocd/                     # ArgoCD manifests
â”‚   â”œâ”€â”€ applications/           # MLflow, MinIO, Postgres, PushGateway, Inference
â”‚   â”‚   â”œâ”€â”€ inference.yaml
â”‚   â”‚   â”œâ”€â”€ minio.yaml
â”‚   â”‚   â”œâ”€â”€ mlflow.yaml
â”‚   â”‚   â”œâ”€â”€ postgres.yaml
â”‚   â”‚   â””â”€â”€ pushgateway.yaml
â”‚   â””â”€â”€ namespaces/             # Namespace definitions
â”‚       â”œâ”€â”€ mlflow-namespace.yaml
â”‚       â””â”€â”€ monitoring-namespace.yaml
â”œâ”€â”€ best_model/                 # Best model exported by training
â”‚   â”œâ”€â”€ MLmodel
â”‚   â”œâ”€â”€ model.pkl
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ conda.yaml
â”‚   â”œâ”€â”€ python_env.yaml
â”‚   â”œâ”€â”€ input_example.json
â”‚   â””â”€â”€ serving_input_example.json
â”œâ”€â”€ mlops-core/
â”‚   â”œâ”€â”€ charts/inference/       # Helm chart for inference service
â”‚   â”‚   â”œâ”€â”€ Chart.yaml
â”‚   â”‚   â”œâ”€â”€ values.yaml
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚       â”œâ”€â”€ deployment.yaml
â”‚   â”‚       â”œâ”€â”€ ingress.yaml
â”‚   â”‚       â”œâ”€â”€ service.yaml
â”‚   â”‚       â””â”€â”€ _helpers.tpl
â”‚   â”œâ”€â”€ inference/              # Inference service (FastAPI + Uvicorn)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ expectations.json
â”‚   â”œâ”€â”€ model/                  # Training & promotion scripts
â”‚   â”‚   â”œâ”€â”€ train_and_push.py
â”‚   â”‚   â”œâ”€â”€ promote.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ best_model/         # Copy of best model after training
â”‚   â”‚       â”œâ”€â”€ MLmodel
â”‚   â”‚       â”œâ”€â”€ model.pkl
â”‚   â”‚       â”œâ”€â”€ requirements.txt
â”‚   â”‚       â”œâ”€â”€ conda.yaml
â”‚   â”‚       â””â”€â”€ python_env.yaml
â”‚   â””â”€â”€ simulate_drift.sh       # Drift simulation script
â””â”€â”€ README.md
```

---

## ğŸš€ Prerequisites

- **Minikube** (or Kubernetes cluster)
- **kubectl**
- **ArgoCD** (deployed in `infra-tools`)
- **Docker** (to build inference image)
- **Python 3.10+** for training scripts

---

## ğŸ—ï¸ Deploy Infrastructure on Minikube

### 1. Start Minikube

```bash
minikube start --cpus=4 --memory=8192 --driver=docker
```

(Optional) Enable registry:

```bash
minikube addons enable registry
```

### 2. Apply Namespaces

```bash
kubectl apply -f argocd/namespaces/
```

### 3. Deploy Applications

```bash
kubectl apply -f argocd/applications/
```

Check:

```bash
argocd app list
```

---

## ğŸ”‘ ArgoCD UI

Forward ArgoCD:

```bash
kubectl port-forward svc/argocd-server -n infra-tools 8080:443
argocd login localhost:8080 --insecure --username admin --password <your-password>
```

---

## ğŸ“Š Services

### MLflow

```bash
kubectl -n mlflow port-forward svc/mlflow-mlflow 5000:5000
```

Access: [http://localhost:5000](http://localhost:5000)

### PushGateway

```bash
kubectl -n monitoring port-forward svc/pushgateway-prometheus-pushgateway 9091:9091
```

Access: [http://localhost:9091](http://localhost:9091)

---

## ğŸ§ª Training & Promotion

### Setup environment

```bash
cd mlops-core/model
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Train & log to MLflow

```bash
python train_and_push.py
```

This will:

- Train SGDClassifier on Iris
- Log to MLflow
- Push metrics to PushGateway
- Copy best model to `best_model/`

### Promote best model

```bash
python promote.py
```

Promotion rules:

- Accuracy â‰¥ `PROMOTE_MIN_ACCURACY` (default 0.9)
- Archives old version in Production
- Sets alias `Production`

---

## ğŸ³ Build Inference Service

```bash
cd mlops-core/inference
docker build -t localhost:5000/inference:0.1.2 .
docker push localhost:5000/inference:0.1.2
```

ArgoCD app `inference.yaml` uses this image.

---

## âš¡ Inference API

Namespace: `inference`  
Service: FastAPI + Uvicorn on `:8080`

Endpoints:

- `GET /healthz`
- `GET /readyz`
- `POST /predict`
- `GET /metrics` (on port `8001`)

### Test

```bash
kubectl -n inference port-forward svc/inference 8080:8080
```

Health:

```bash
curl http://localhost:8080/healthz
```

Predict (list):

```bash
curl -X POST http://localhost:8080/predict \
  -H "Content-Type: application/json" \
  -d '{"instances": [[5.1, 3.5, 1.4, 0.2], [6.2, 3.4, 5.4, 2.3]]}'
```

Predict (dict):

```bash
curl -X POST http://localhost:8080/predict \
  -H "Content-Type: application/json" \
  -d '{
    "instances": [
      {"sepal length (cm)": 5.1, "sepal width (cm)": 3.5, "petal length (cm)": 1.4, "petal width (cm)": 0.2},
      {"sepal length (cm)": 6.2, "sepal width (cm)": 3.4, "petal length (cm)": 5.4, "petal width (cm)": 2.3}
    ]
  }'
```

---

## ğŸ“‰ Drift Simulation

```bash
kubectl -n inference port-forward svc/inference 8080:8080
cd mlops-core
chmod +x simulate_drift.sh
./simulate_drift.sh
```

This will send baseline + drifted requests.

---

## ğŸ“ˆ Monitoring in Grafana

```bash
kubectl -n monitoring port-forward svc/grafana 8081:80
```

Access: [http://localhost:8081](http://localhost:8081)  
Login: `admin/mlops` â†’ Dashboard â†’ *Inference Service Overview*

---

## âœ… Summary

- Full MLOps workflow: **MLflow + MinIO + Postgres + ArgoCD + FastAPI + Prometheus**
- Train/promote pipeline with metrics-based promotion
- Containerized inference with drift detection
- Ready to run in Minikube or production Kubernetes

## ğŸ”„ Typical Workflow (Step-by-Step)

1. **Start Minikube cluster**  

   ```bash
   minikube start --cpus=4 --memory=8192 --driver=docker
   ```

2. **Apply namespaces**  

   ```bash
   kubectl apply -f argocd/namespaces/
   ```

3. **Deploy applications via ArgoCD**  

   ```bash
   kubectl apply -f argocd/applications/
   ```

4. **Access ArgoCD UI**  

   ```bash
   kubectl port-forward svc/argocd-server -n infra-tools 8080:443
   argocd login localhost:8080 --insecure --username admin --password <your-password>
   ```

5. **Port-forward key services**  

   ```bash
   # MLflow
   kubectl -n mlflow port-forward svc/mlflow-mlflow 5000:5000

   # MinIO
   kubectl -n mlflow port-forward svc/minio 9000:9000

   # Postgres
   kubectl -n mlflow port-forward svc/postgres-postgresql 5432:5432

   # PushGateway
   kubectl -n monitoring port-forward svc/pushgateway-prometheus-pushgateway 9091:9091

   # Grafana
   kubectl -n monitoring port-forward svc/grafana 8081:80

   # Inference API
   kubectl -n inference port-forward svc/inference 8080:8080
   ```

6. **Run training & select best model**  

   ```bash
   cd mlops-core/model
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt

   python train_and_push.py
   python promote.py
   ```

7. **Build & push inference image**  

   ```bash
   cd mlops-core/inference
   docker build -t localhost:5000/inference:0.1.2 .
   docker push localhost:5000/inference:0.1.2
   ```

8. **Test inference service**  

   ```bash
   curl http://localhost:8080/healthz
   curl -X POST http://localhost:8080/predict \
     -H "Content-Type: application/json" \
     -d '{"instances": [[5.1, 3.5, 1.4, 0.2]]}'
   ```

9. **Simulate drift**  

   ```bash
   cd mlops-core
   ./simulate_drift.sh
   ```

10. **Monitor in Grafana**  
    Open: [http://localhost:8081](http://localhost:8081) â†’ Dashboard â†’ *Inference Service Overview*
